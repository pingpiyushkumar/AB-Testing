{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project - A/B Testing\n",
    "Author: Piyush Kumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A/B tests are used to test changes on a web page (from large feature additions to small adjustments in color) by running an experiment where a **control** group sees the old version, while the **experiment** group sees the new version. A **metric or group of metric** is then chosen to measure the level of engagement from users in each group. These results are then used to judge whether one version is more effective than the other. A/B testing is very much like hypothesis testing with the following hypotheses:\n",
    "\n",
    "- **Null Hypothesis:**  The new version is no better, or even worse, than the old version.\n",
    "- **Alternative Hypothesis:**  The new version is better than the old version.\n",
    "\n",
    "If we fail to reject the null hypothesis, the results would suggest keeping the old version. If we reject the null hypothesis, the results would suggest launching the change. That's enough background, let's dive in!\n",
    "\n",
    "### Table of Contents:\n",
    "\n",
    "- [Introduction](#intro)\n",
    "- [Part I - Probability](#probability)\n",
    "- [Part II - A/B Test](#ab_test)\n",
    "- [Part III - Regression Approach](#regression)\n",
    "\n",
    "<a id=intro></a>\n",
    "### Introduction \n",
    "\n",
    "An ecommerce company has developed a new web page in order to try and increase the number of users who \"convert,\" meaning the number of users who decide to pay for the company's product. Our goal is to help the company understand if they should implement this new page, keep the old page, or perhaps run the experiment longer to make their decision, by analyzing the A/B tests run by company. \n",
    "\n",
    "Our metric for this A/B test would be whether the user converts or not. \n",
    "\n",
    "<a id=probability></a>\n",
    "### Part I - Probability \n",
    "\n",
    "To get started, let's import our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# let's setup a random seed so that the results obtanined here don't deviate on future runs of this notebook. \n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                   timestamp      group landing_page  converted\n",
       "0   851104  2017-01-21 22:11:48.556739    control     old_page          0\n",
       "1   804228  2017-01-12 08:01:45.159739    control     old_page          0\n",
       "2   661590  2017-01-11 16:55:06.154213  treatment     new_page          0\n",
       "3   853541  2017-01-08 18:28:03.143765  treatment     new_page          0\n",
       "4   864975  2017-01-21 01:52:26.210827    control     old_page          1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's load the a/b test data and take a look into the few top rows.\n",
    "\n",
    "df=pd.read_csv(\"ab_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294478, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get the shape of our dataset.\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique users in our dataset.\n",
    "\n",
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check for any duplciate rows we might have.\n",
    "\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id         0\n",
       "timestamp       0\n",
       "group           0\n",
       "landing_page    0\n",
       "converted       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check for any null values we might have.\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      "user_id         294478 non-null int64\n",
      "timestamp       294478 non-null object\n",
      "group           294478 non-null object\n",
      "landing_page    294478 non-null object\n",
      "converted       294478 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# let's get a broadview of our dataset. \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have incorrect datatype here, object type for `timestamp` instead of datetime and int type for `converted` instead of bool. Fixing the datatype is not the objective here, but let's fix the timestamp column so as we can get the runtime of A/B test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 294478 entries, 0 to 294477\n",
      "Data columns (total 5 columns):\n",
      "user_id         294478 non-null int64\n",
      "timestamp       294478 non-null datetime64[ns]\n",
      "group           294478 non-null object\n",
      "landing_page    294478 non-null object\n",
      "converted       294478 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(2), object(2)\n",
      "memory usage: 11.2+ MB\n"
     ]
    }
   ],
   "source": [
    "# Changing timestamp column into datetime type and checking for the changes made. \n",
    "\n",
    "df.timestamp=pd.to_datetime(df.timestamp)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('21 days 23:59:49.081927')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the Runtime of A/B test.\n",
    "\n",
    "df.timestamp.max() - df.timestamp.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 22 days of runtime for this A/B test seems satisfactory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2017-01-02     5783\n",
       "2017-01-03    13394\n",
       "2017-01-04    13284\n",
       "2017-01-05    13124\n",
       "2017-01-06    13528\n",
       "2017-01-07    13381\n",
       "2017-01-08    13564\n",
       "2017-01-09    13439\n",
       "2017-01-10    13523\n",
       "2017-01-11    13553\n",
       "2017-01-12    13322\n",
       "2017-01-13    13238\n",
       "2017-01-14    13329\n",
       "2017-01-15    13449\n",
       "2017-01-16    13327\n",
       "2017-01-17    13322\n",
       "2017-01-18    13285\n",
       "2017-01-19    13293\n",
       "2017-01-20    13393\n",
       "2017-01-21    13475\n",
       "2017-01-22    13423\n",
       "2017-01-23    13511\n",
       "2017-01-24     7538\n",
       "Name: timestamp, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also see the date-wise distribution of A/B test users. \n",
    "\n",
    "df.timestamp.dt.date.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a uniform distrubution of A/B test users across days for the running period of the A/B test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3893"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if there are any instances where treatment group doesn't match with new_page\n",
    "# and control group doesn't match with old_page\n",
    "\n",
    "df[(df['group']=='treatment') & (df['landing_page']!='new_page')].shape[0] + df[(df['group']=='control') & (df['landing_page']!='old_page')].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these 3893 rows, we are not sure if it received the new_page or the old_page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's delete these new found instances which otherwise can make our analysis flawed. \n",
    "\n",
    "df.drop(df[(df['group']=='treatment') & (df['landing_page']!='new_page')].index, inplace=True)\n",
    "df.drop(df[(df['group']=='control') & (df['landing_page']!='old_page')].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if correct rows are removed - the following expression should be zero. \n",
    "\n",
    "df[(df['group']=='treatment') & (df['landing_page']!='new_page')].shape[0] + df[(df['group']=='control') & (df['landing_page']!='old_page')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duplicate users in our dataset.\n",
    "\n",
    "df.user_id.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2893    773192\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bringing up that duplicate user_id.\n",
    "\n",
    "df[df.user_id.duplicated()==True].user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1899</td>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2893</td>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-14 02:55:59.590927</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                  timestamp      group landing_page  converted\n",
       "1899   773192 2017-01-09 05:37:58.781806  treatment     new_page          0\n",
       "2893   773192 2017-01-14 02:55:59.590927  treatment     new_page          0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspecting all the rows of the duplicate user_id.\n",
    "\n",
    "df[df.user_id==773192]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the entries above are indifferent to `group`, `landing_page` and `converted`. We can remove any of these rows. Phew!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1899</td>\n",
       "      <td>773192</td>\n",
       "      <td>2017-01-09 05:37:58.781806</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id                  timestamp      group landing_page  converted\n",
       "1899   773192 2017-01-09 05:37:58.781806  treatment     new_page          0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping the row with duplicate user_id.\n",
    "\n",
    "df.drop_duplicates('user_id', inplace=True)\n",
    "df[df['user_id']==773192]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how many unique users we have now.\n",
    "\n",
    "df.user_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of users who got converted, regardless of the type of the landing_page they received.\n",
    "\n",
    "df.converted.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1203863045004612"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of control group users who got convereted\n",
    "\n",
    "control=df[df.group =='control']\n",
    "control.converted.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11880806551510564"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability of treatment group users who got convereted\n",
    "\n",
    "treatment=df[df.group=='treatment']\n",
    "treatment.converted.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5000619442226688"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probability that a user receives the new_page.\n",
    "\n",
    "df[df.landing_page =='new_page'].shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145274"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of users in the control group. \n",
    "\n",
    "n_old = control.shape[0]\n",
    "n_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145310"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of users in the treatment group. \n",
    "\n",
    "n_new = treatment.shape[0]\n",
    "n_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost equal no. of users in our control and treatment group, and a 50% probability of an user receiving the new page indicates that we have balancned set of users in both the groups and an equally likely probability of getting either of the two pages. However, the probabilty of conversion is even lower with the new page than the old page, and is also the same as the probabilty of conversion irrespective of page, hence it's not a good idea to implement the new page design. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ab_test'></a>\n",
    "### Part II - A/B Test\n",
    "\n",
    "We want to assume that the old page is better unless the new page proves to be definitely better at a Type I error rate of 5%.\n",
    "<br>This sets up our null and alternative hypothesis like:\n",
    "\n",
    "$$ H_0: p_{new} <= p_{old}$$\n",
    "\n",
    "$$ H_1: p_{new} > p_{old}$$\n",
    "\n",
    "$$\\alpha = 0.05$$\n",
    "\n",
    "Where $p_{new}$ and $p_{old}$ are the converted rate for the `new_page` and `old_page` respectively.\n",
    "\n",
    "Since our motive is to find which page has more conversion rate, let's assume under the null hypothesis that, $p_{new}$ and $p_{old}$ both have equal conversion rates. Furthermore, assume they are equal to the **converted** rate in our **ab_data.csv** dataset regardless of the page. <br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In line with our assumption, the conversion rate for p_new under the null\n",
    "\n",
    "p_new = df.converted.mean()\n",
    "p_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11959708724499628"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And, the conversion rate for the p_old under the null\n",
    "\n",
    "p_old = df.converted.mean()\n",
    "p_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(145274, 145310)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No. of users in the control and treatment group. \n",
    "\n",
    "n_old, n_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's simulate n_old transactions with a conversion rate of p_old under the null\n",
    "\n",
    "old_page_converted = np.random.choice(2, size=n_old, p=[1-p_old,p_old])\n",
    "old_page_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's simulate n_new transactions with a conversion rate of p_new under the null\n",
    "\n",
    "new_page_converted = np.random.choice(2, size=n_new, p=[1-p_new, p_new])\n",
    "new_page_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011131312957196743"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observed difference in the simulated conversion rates for the old_page and the new_page\n",
    "\n",
    "obs_diff = new_page_converted.mean() - old_page_converted.mean()\n",
    "obs_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's perform a sampling distribution of the difference in conversion rates \n",
    "# for the new_page and old_page over 10000 iterations \n",
    "\n",
    "p_diffs = []\n",
    "for i in range(10000):\n",
    "    new_page_converted = np.random.choice(2, size=n_new, p=[1-p_new, p_new])\n",
    "    old_page_converted = np.random.choice(2, size=n_old, p=[1-p_old, p_old])\n",
    "    obs_diff_sample = new_page_converted.mean() - old_page_converted.mean()\n",
    "    p_diffs.append(obs_diff_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot this simulated difference in conversion rates.\n",
    "\n",
    "p_diffs=np.array(p_diffs)\n",
    "plt.hist(p_diffs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling distribution for our statistic (diff. in means) is normally distributed. This confirms that our sample size conforms to central limit theorem.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9069"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compute the proportion of p_diffs that is greater than the \n",
    "# actual difference observed for the conversion rates in our dataset\n",
    "\n",
    "(p_diffs> (treatment.converted.mean() - control.converted.mean())).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is called p-value. The probability of observing our statistic from the null hypothesis.\n",
    "We'd set up our hypothesis with the type-I error rate of 0.05, and the obtained p-value is large enough and greater than $\\alpha$ as well, so we fail to reject the null.\n",
    "And hence, we have the evidence that with a type I error rate of 0.05 old_page has higher or equal probablity of converting than the new_page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a built-in `stats.proportions_ztest` from statsmodels library to achieve similar results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get the count of conversions for old_page and new_page\n",
    "\n",
    "convert_old = control[control['converted']==1].shape[0]\n",
    "convert_new = treatment[treatment['converted']==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3109241984234394, 0.9050583127590245)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, let's run the Z-statistic test to get the z-score and p_value\n",
    "\n",
    "z_score, p_value = sm.stats.proportions_ztest(np.array([convert_old,convert_new]),np.array([n_old,n_new]), alternative = 'smaller')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.959963984540054"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's see what's the critical value is at our z-score:\n",
    "\n",
    "from scipy.stats import norm\n",
    "norm.ppf(1-(0.05/2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our z-score of 1.3109241984234394 is not more than the critical value of z-score of 1.959963984540054. We fail to reject the null hypothesis that new page users has a better or equal converted rate than old page users. Also, the p_value is large enough that we fail to reject our null hypothesis. \n",
    "\n",
    "And hence, we have the evidence that with a type I error rate of 0.05 old_page has higher or equal probablity of converting than the new_page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=regression></a>\n",
    "### Part III - Regression Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results obtained via A/B test can also be achieved by performing regression.\n",
    "\n",
    "Since each row is either a conversion or no conversion, i.e our target variable is of categorical type, we will use Logistics regression in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>215191</td>\n",
       "      <td>907982</td>\n",
       "      <td>2017-01-23 04:19:34.773108</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140268</td>\n",
       "      <td>844643</td>\n",
       "      <td>2017-01-19 01:46:06.193214</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47432</td>\n",
       "      <td>866373</td>\n",
       "      <td>2017-01-05 05:07:30.633476</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228975</td>\n",
       "      <td>762608</td>\n",
       "      <td>2017-01-11 11:04:34.121551</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50074</td>\n",
       "      <td>679492</td>\n",
       "      <td>2017-01-09 14:07:23.918512</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                  timestamp      group landing_page  converted  \\\n",
       "215191   907982 2017-01-23 04:19:34.773108  treatment     new_page          0   \n",
       "140268   844643 2017-01-19 01:46:06.193214    control     old_page          1   \n",
       "47432    866373 2017-01-05 05:07:30.633476  treatment     new_page          0   \n",
       "228975   762608 2017-01-11 11:04:34.121551    control     old_page          0   \n",
       "50074    679492 2017-01-09 14:07:23.918512    control     old_page          0   \n",
       "\n",
       "        ab_page  \n",
       "215191        1  \n",
       "140268        0  \n",
       "47432         1  \n",
       "228975        0  \n",
       "50074         0  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dummy variable ab_page which will be 1 if the user receives the new_page and 0 if old_page \n",
    "\n",
    "df['ab_page'] = pd.get_dummies(df['group'])['treatment']\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366118\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# let's build the logistics regression model\n",
    "\n",
    "df['intercept']= 1  \n",
    "model = sm.Logit(df['converted'], df[['intercept','ab_page']])\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290582</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     1</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 15 Jul 2020</td> <th>  Pseudo R-squ.:     </th>  <td>8.077e-06</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:28:45</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1899</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0150</td> <td>    0.011</td> <td>   -1.311</td> <td> 0.190</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290582\n",
       "Method:                           MLE   Df Model:                            1\n",
       "Date:                Wed, 15 Jul 2020   Pseudo R-squ.:               8.077e-06\n",
       "Time:                        20:28:45   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1899\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0150      0.011     -1.311      0.190      -0.037       0.007\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get the summary statistics for our model\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value here is 0.190. It differs from the previous as the hypotheses are different for this regression approach.\n",
    "The null hypothesis here is that there is no difference between the treatment and control group.\n",
    "Alternative hypotheses is that there is difference between the treatment and control group. Since, the p-value here is greater than the type-I error rate threshold ($\\alpha$) of 0.05, we fail to reject the null hypothesis. \n",
    "\n",
    "<br>\n",
    "\n",
    "We can also consider impact of other factors that might influence whether or not an user converts. Among other factors to consider, we can go with duration i.e timestamp variable, location of the user. Viability of the same is a tradeoff between performance gain and the question that if we really need that added complexity into the model. Though, adding additional factors into your model might lead to better prediction, it will also make the model complex, will take longer time to train and is generally not a good idea to go with if the performance gains aren't big enough. \n",
    "\n",
    "Let's test the above idea and include the country of the user in our regression model and see if there's an impact on the conversion based on which country a user lives in.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>834778</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>928468</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>822059</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>711597</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>710616</td>\n",
       "      <td>UK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id country\n",
       "0   834778      UK\n",
       "1   928468      US\n",
       "2   822059      UK\n",
       "3   711597      UK\n",
       "4   710616      UK"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's read in the countries dataset\n",
    "\n",
    "countries=pd.read_csv('countries.csv')\n",
    "countries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id    0\n",
       "country    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do some basic checks\n",
    "\n",
    "countries.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values! Sorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "290584"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see how many unique users we have here.\n",
    "\n",
    "countries.user_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is equal to the no. of unique users in our `ab_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    203619\n",
       "UK     72466\n",
       "CA     14499\n",
       "Name: country, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the no. of users from each country\n",
    "\n",
    "countries.country.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>851104</td>\n",
       "      <td>2017-01-21 22:11:48.556739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>804228</td>\n",
       "      <td>2017-01-12 08:01:45.159739</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>661590</td>\n",
       "      <td>2017-01-11 16:55:06.154213</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>853541</td>\n",
       "      <td>2017-01-08 18:28:03.143765</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>864975</td>\n",
       "      <td>2017-01-21 01:52:26.210827</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                  timestamp      group landing_page  converted  \\\n",
       "0   851104 2017-01-21 22:11:48.556739    control     old_page          0   \n",
       "1   804228 2017-01-12 08:01:45.159739    control     old_page          0   \n",
       "2   661590 2017-01-11 16:55:06.154213  treatment     new_page          0   \n",
       "3   853541 2017-01-08 18:28:03.143765  treatment     new_page          0   \n",
       "4   864975 2017-01-21 01:52:26.210827    control     old_page          1   \n",
       "\n",
       "   ab_page  intercept country  \n",
       "0        0          1      US  \n",
       "1        0          1      US  \n",
       "2        1          1      US  \n",
       "3        1          1      US  \n",
       "4        0          1      US  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's merge the two datasets on user_id as the primary key. \n",
    "\n",
    "df2 = df.merge(countries, on ='user_id', how='left')\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "CA     1672\n",
       "UK     8739\n",
       "US    24342\n",
       "Name: converted, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's see how many users got converted from each country\n",
    "\n",
    "df2[df2['converted']==1].groupby(['country'])['converted'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>group</th>\n",
       "      <th>landing_page</th>\n",
       "      <th>converted</th>\n",
       "      <th>ab_page</th>\n",
       "      <th>intercept</th>\n",
       "      <th>country</th>\n",
       "      <th>country_CA</th>\n",
       "      <th>country_UK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>6880</td>\n",
       "      <td>871290</td>\n",
       "      <td>2017-01-06 14:19:16.439134</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238351</td>\n",
       "      <td>889782</td>\n",
       "      <td>2017-01-23 13:28:00.339523</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27483</td>\n",
       "      <td>945423</td>\n",
       "      <td>2017-01-03 19:03:23.983641</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124856</td>\n",
       "      <td>796523</td>\n",
       "      <td>2017-01-16 18:56:32.556205</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>UK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2682</td>\n",
       "      <td>658478</td>\n",
       "      <td>2017-01-16 04:08:50.963618</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187257</td>\n",
       "      <td>835802</td>\n",
       "      <td>2017-01-10 23:04:24.421868</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>269920</td>\n",
       "      <td>864890</td>\n",
       "      <td>2017-01-04 17:53:12.025636</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142804</td>\n",
       "      <td>806714</td>\n",
       "      <td>2017-01-12 10:13:14.713968</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229976</td>\n",
       "      <td>639081</td>\n",
       "      <td>2017-01-11 19:04:03.827149</td>\n",
       "      <td>control</td>\n",
       "      <td>old_page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49177</td>\n",
       "      <td>703778</td>\n",
       "      <td>2017-01-02 13:52:44.656037</td>\n",
       "      <td>treatment</td>\n",
       "      <td>new_page</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id                  timestamp      group landing_page  converted  \\\n",
       "6880     871290 2017-01-06 14:19:16.439134    control     old_page          0   \n",
       "238351   889782 2017-01-23 13:28:00.339523    control     old_page          0   \n",
       "27483    945423 2017-01-03 19:03:23.983641  treatment     new_page          0   \n",
       "124856   796523 2017-01-16 18:56:32.556205  treatment     new_page          0   \n",
       "2682     658478 2017-01-16 04:08:50.963618    control     old_page          0   \n",
       "187257   835802 2017-01-10 23:04:24.421868  treatment     new_page          0   \n",
       "269920   864890 2017-01-04 17:53:12.025636    control     old_page          0   \n",
       "142804   806714 2017-01-12 10:13:14.713968    control     old_page          0   \n",
       "229976   639081 2017-01-11 19:04:03.827149    control     old_page          0   \n",
       "49177    703778 2017-01-02 13:52:44.656037  treatment     new_page          0   \n",
       "\n",
       "        ab_page  intercept country  country_CA  country_UK  \n",
       "6880          0          1      UK           0           1  \n",
       "238351        0          1      US           0           0  \n",
       "27483         1          1      UK           0           1  \n",
       "124856        1          1      UK           0           1  \n",
       "2682          0          1      US           0           0  \n",
       "187257        1          1      US           0           0  \n",
       "269920        0          1      US           0           0  \n",
       "142804        0          1      US           0           0  \n",
       "229976        0          1      US           0           0  \n",
       "49177         1          1      US           0           0  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dummy variables for the each of the three countries CA, US and UK\n",
    "\n",
    "df2['country_CA'] = pd.get_dummies(df2['country'])['CA']\n",
    "df2['country_UK'] = pd.get_dummies(df2['country'])['UK']\n",
    "df2.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366113\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# let's instantiate and fit the logistics model.\n",
    "\n",
    "model2 = sm.Logit(df2['converted'], df2[['intercept','ab_page', 'country_CA', 'country_UK']])\n",
    "results2 = model2.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 15 Jul 2020</td> <th>  Pseudo R-squ.:     </th>  <td>2.323e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:47:57</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.1760</td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>  <td>   -1.9893</td> <td>    0.009</td> <td> -223.763</td> <td> 0.000</td> <td>   -2.007</td> <td>   -1.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>    <td>   -0.0149</td> <td>    0.011</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.037</td> <td>    0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>country_CA</th> <td>   -0.0408</td> <td>    0.027</td> <td>   -1.516</td> <td> 0.130</td> <td>   -0.093</td> <td>    0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>country_UK</th> <td>    0.0099</td> <td>    0.013</td> <td>    0.743</td> <td> 0.457</td> <td>   -0.016</td> <td>    0.036</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Wed, 15 Jul 2020   Pseudo R-squ.:               2.323e-05\n",
       "Time:                        20:47:57   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                    0.1760\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9893      0.009   -223.763      0.000      -2.007      -1.972\n",
       "ab_page       -0.0149      0.011     -1.307      0.191      -0.037       0.007\n",
       "country_CA    -0.0408      0.027     -1.516      0.130      -0.093       0.012\n",
       "country_UK     0.0099      0.013      0.743      0.457      -0.016       0.036\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get the summary statistics for our model\n",
    "\n",
    "results2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "None of the individual factors above have a p-value of less than the type-I error rate threshold ($\\alpha$) of 0.05. \n",
    "We cannot conclude that the country, page type and conversions are co-related.\n",
    "\n",
    "Moving from individual factors, now let's see if the interaction terms has any effect on conversion. Let's fit a new model to include the interaction between countries and page type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.366109\n",
      "         Iterations 6\n"
     ]
    }
   ],
   "source": [
    "# let's create the interaction terms out of dummy variables of countries and ab_page, and then fit the new model.\n",
    "\n",
    "df2['ab_CA'] = df2['ab_page'] * df2['country_CA']\n",
    "df2['ab_UK'] = df2['ab_page'] * df2['country_UK']\n",
    "\n",
    "model3 = sm.Logit(df2['converted'], df2[['intercept', 'ab_page', 'ab_CA', 'ab_UK']])\n",
    "results3 = model3.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>converted</td>    <th>  No. Observations:  </th>   <td>290584</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>290580</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     3</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 16 Jul 2020</td> <th>  Pseudo R-squ.:     </th>  <td>3.351e-05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>00:41:54</td>     <th>  Log-Likelihood:    </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td>-1.0639e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>   <td>0.06785</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -1.9888</td> <td>    0.008</td> <td> -246.669</td> <td> 0.000</td> <td>   -2.005</td> <td>   -1.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_page</th>   <td>   -0.0183</td> <td>    0.013</td> <td>   -1.449</td> <td> 0.147</td> <td>   -0.043</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_CA</th>     <td>   -0.0644</td> <td>    0.038</td> <td>   -1.679</td> <td> 0.093</td> <td>   -0.140</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ab_UK</th>     <td>    0.0257</td> <td>    0.019</td> <td>    1.363</td> <td> 0.173</td> <td>   -0.011</td> <td>    0.063</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              converted   No. Observations:               290584\n",
       "Model:                          Logit   Df Residuals:                   290580\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Thu, 16 Jul 2020   Pseudo R-squ.:               3.351e-05\n",
       "Time:                        00:41:54   Log-Likelihood:            -1.0639e+05\n",
       "converged:                       True   LL-Null:                   -1.0639e+05\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.06785\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "intercept     -1.9888      0.008   -246.669      0.000      -2.005      -1.973\n",
       "ab_page       -0.0183      0.013     -1.449      0.147      -0.043       0.006\n",
       "ab_CA         -0.0644      0.038     -1.679      0.093      -0.140       0.011\n",
       "ab_UK          0.0257      0.019      1.363      0.173      -0.011       0.063\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's get the summary statistics for our model\n",
    "\n",
    "results3.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, none of the interaction terms above has a p-value of less than the type-I error rate threshold (  ) of 0.05. We cannot conclude that the interaction between country and page type results in a conversions or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=conclusion></a>\n",
    "### Conclusion\n",
    "\n",
    "Based on the results obtained from different approaches, we conclude that we don't have sufficient evidence to prove that implementing `new_page` will lead to more conversion than the `old_page`. \n",
    "\n",
    "Hence, the recommendation is to not launch the new page design and keep up with the old design. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
